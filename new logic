import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.*;

import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import java.util.List;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;

public class S3Service {

    private final S3Client s3Client;
    private final ThreadPoolTaskExecutor taskExecutor;
    private final BlockingQueue<List<S3Object>> queue = new LinkedBlockingQueue<>(10);

    public S3Service(S3Client s3Client) {
        this.s3Client = s3Client;

        // Initialize ThreadPool
        this.taskExecutor = new ThreadPoolTaskExecutor();
        this.taskExecutor.setCorePoolSize(3); // Number of parallel fetchers
        this.taskExecutor.setMaxPoolSize(5);
        this.taskExecutor.setQueueCapacity(10);
        this.taskExecutor.initialize();
    }

    public void fetchAndProcessS3Objects(int targetCount) {
        int maxKeys = 1000; // Each request fetches max 1000 objects
        int requiredRequests = (int) Math.ceil((double) targetCount / maxKeys); // Calculate required fetches

        ExecutorService fetcherPool = Executors.newSingleThreadExecutor(); // Single fetcher task
        ExecutorService processorPool = Executors.newSingleThreadExecutor(); // Single processor

        final String bucketName = "your-bucket-name";
        final AtomicInteger totalCount = new AtomicInteger(0);
        final AtomicReference<String> continuationToken = new AtomicReference<>(null);

        // Single Fetcher Task that loops internally
        fetcherPool.submit(() -> {
            for (int i = 0; i < requiredRequests; i++) {
                if (totalCount.get() >= targetCount) break;

                ListObjectsV2Request request = ListObjectsV2Request.builder()
                    .bucket(bucketName)
                    .maxKeys(maxKeys)
                    .continuationToken(continuationToken.get())
                    .build();

                ListObjectsV2Response response = s3Client.listObjectsV2(request);
                if (response.contents().isEmpty()) break; // Stop if no more objects

                try {
                    queue.put(response.contents()); // Store in queue
                    totalCount.addAndGet(response.contents().size());
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    return;
                }

                if (!response.isTruncated()) break; // No more objects in S3
                continuationToken.set(response.nextContinuationToken());
            }
        });

        // Processor Task
        processorPool.submit(() -> {
            while (totalCount.get() < targetCount) {
                try {
                    List<S3Object> objects = queue.take();
                    processObjectsInChunks(objects);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
        });

        fetcherPool.shutdown();
        processorPool.shutdown();
    }

    private void processObjectsInChunks(List<S3Object> objects) {
        // Implement chunk processing logic
    }
}